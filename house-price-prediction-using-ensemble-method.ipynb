{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ishaqkhattak/house-price-prediction-using-ensemble-method?scriptVersionId=161157133\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-31T11:12:22.01005Z","iopub.execute_input":"2024-01-31T11:12:22.011145Z","iopub.status.idle":"2024-01-31T11:12:22.464932Z","shell.execute_reply.started":"2024-01-31T11:12:22.011066Z","shell.execute_reply":"2024-01-31T11:12:22.463794Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv\n/kaggle/input/house-prices-advanced-regression-techniques/data_description.txt\n/kaggle/input/house-prices-advanced-regression-techniques/train.csv\n/kaggle/input/house-prices-advanced-regression-techniques/test.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"> 1. Understanding Data\n\n     Univariate Analysis\n     \n     Bi-variate Analysis\n\n> 2. Data Preprocessing\n\n     Removing redundant features\n     \n     Dealing with Outliers\n     \n     Filling Missing Values\n     \n> 3. Feature Engineering\n\n> 5. Modeling\n\n     Scaling of features\n     \n     Ensemble Algorithms","metadata":{}},{"cell_type":"markdown","source":"**NOTE: this notebook is complete in term of results and model implementation but currently working on improving the results.**","metadata":{}},{"cell_type":"markdown","source":"# 1. Understading data","metadata":{}},{"cell_type":"code","source":"import sklearn\nimport matplotlib.pyplot as plt\nimport matplotlib.pyplot as plt\nimport numpy\nimport pandas\nimport seaborn as sns\n# Import pandas profiling library\nimport ydata_profiling as pp\ntest = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')\ntrain = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')","metadata":{"execution":{"iopub.status.busy":"2024-01-31T11:12:34.317133Z","iopub.execute_input":"2024-01-31T11:12:34.317645Z","iopub.status.idle":"2024-01-31T11:12:37.785159Z","shell.execute_reply.started":"2024-01-31T11:12:34.317611Z","shell.execute_reply":"2024-01-31T11:12:37.783848Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/numba/core/decorators.py:262: NumbaDeprecationWarning: \u001b[1mnumba.generated_jit is deprecated. Please see the documentation at: https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-generated-jit for more information and advice on a suitable replacement.\u001b[0m\n  warnings.warn(msg, NumbaDeprecationWarning)\n/opt/conda/lib/python3.10/site-packages/visions/backends/shared/nan_handling.py:51: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n  def hasna(x: np.ndarray) -> bool:\n","output_type":"stream"}]},{"cell_type":"code","source":"#test2.shape, train2['SalePrice'].shape","metadata":{"execution":{"iopub.status.busy":"2024-01-31T11:12:37.787368Z","iopub.execute_input":"2024-01-31T11:12:37.788332Z","iopub.status.idle":"2024-01-31T11:12:37.796746Z","shell.execute_reply.started":"2024-01-31T11:12:37.788282Z","shell.execute_reply":"2024-01-31T11:12:37.794185Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"test.shape, train.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-31T11:12:37.798411Z","iopub.execute_input":"2024-01-31T11:12:37.798893Z","iopub.status.idle":"2024-01-31T11:12:37.81505Z","shell.execute_reply.started":"2024-01-31T11:12:37.798852Z","shell.execute_reply":"2024-01-31T11:12:37.814032Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"((1459, 80), (1460, 81))"},"metadata":{}}]},{"cell_type":"code","source":"train.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T11:12:37.817867Z","iopub.execute_input":"2024-01-31T11:12:37.818236Z","iopub.status.idle":"2024-01-31T11:12:37.85946Z","shell.execute_reply.started":"2024-01-31T11:12:37.818205Z","shell.execute_reply":"2024-01-31T11:12:37.858252Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n\n  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n\n  YrSold  SaleType  SaleCondition  SalePrice  \n0   2008        WD         Normal     208500  \n1   2007        WD         Normal     181500  \n2   2008        WD         Normal     223500  \n3   2006        WD        Abnorml     140000  \n4   2008        WD         Normal     250000  \n\n[5 rows x 81 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>...</th>\n      <th>PoolArea</th>\n      <th>PoolQC</th>\n      <th>Fence</th>\n      <th>MiscFeature</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>208500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>181500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>223500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>70</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Abnorml</td>\n      <td>140000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>250000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 81 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"So, i have just seen few of NAN value which mean some values are empty.","metadata":{}},{"cell_type":"code","source":"X = pd.concat([train.drop(\"SalePrice\", axis=1),test], axis=0)\ny = train[['SalePrice']]","metadata":{"execution":{"iopub.status.busy":"2024-01-31T11:12:41.07597Z","iopub.execute_input":"2024-01-31T11:12:41.076865Z","iopub.status.idle":"2024-01-31T11:12:41.09897Z","shell.execute_reply.started":"2024-01-31T11:12:41.076823Z","shell.execute_reply":"2024-01-31T11:12:41.097745Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"X.shape,y.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-31T11:12:42.160743Z","iopub.execute_input":"2024-01-31T11:12:42.161186Z","iopub.status.idle":"2024-01-31T11:12:42.168932Z","shell.execute_reply.started":"2024-01-31T11:12:42.161149Z","shell.execute_reply":"2024-01-31T11:12:42.16769Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"((2919, 80), (1460, 1))"},"metadata":{}}]},{"cell_type":"code","source":"X.info()","metadata":{"execution":{"iopub.status.busy":"2024-01-31T11:12:43.394865Z","iopub.execute_input":"2024-01-31T11:12:43.395287Z","iopub.status.idle":"2024-01-31T11:12:43.444278Z","shell.execute_reply.started":"2024-01-31T11:12:43.395254Z","shell.execute_reply":"2024-01-31T11:12:43.443119Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 2919 entries, 0 to 1458\nData columns (total 80 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   Id             2919 non-null   int64  \n 1   MSSubClass     2919 non-null   int64  \n 2   MSZoning       2915 non-null   object \n 3   LotFrontage    2433 non-null   float64\n 4   LotArea        2919 non-null   int64  \n 5   Street         2919 non-null   object \n 6   Alley          198 non-null    object \n 7   LotShape       2919 non-null   object \n 8   LandContour    2919 non-null   object \n 9   Utilities      2917 non-null   object \n 10  LotConfig      2919 non-null   object \n 11  LandSlope      2919 non-null   object \n 12  Neighborhood   2919 non-null   object \n 13  Condition1     2919 non-null   object \n 14  Condition2     2919 non-null   object \n 15  BldgType       2919 non-null   object \n 16  HouseStyle     2919 non-null   object \n 17  OverallQual    2919 non-null   int64  \n 18  OverallCond    2919 non-null   int64  \n 19  YearBuilt      2919 non-null   int64  \n 20  YearRemodAdd   2919 non-null   int64  \n 21  RoofStyle      2919 non-null   object \n 22  RoofMatl       2919 non-null   object \n 23  Exterior1st    2918 non-null   object \n 24  Exterior2nd    2918 non-null   object \n 25  MasVnrType     1153 non-null   object \n 26  MasVnrArea     2896 non-null   float64\n 27  ExterQual      2919 non-null   object \n 28  ExterCond      2919 non-null   object \n 29  Foundation     2919 non-null   object \n 30  BsmtQual       2838 non-null   object \n 31  BsmtCond       2837 non-null   object \n 32  BsmtExposure   2837 non-null   object \n 33  BsmtFinType1   2840 non-null   object \n 34  BsmtFinSF1     2918 non-null   float64\n 35  BsmtFinType2   2839 non-null   object \n 36  BsmtFinSF2     2918 non-null   float64\n 37  BsmtUnfSF      2918 non-null   float64\n 38  TotalBsmtSF    2918 non-null   float64\n 39  Heating        2919 non-null   object \n 40  HeatingQC      2919 non-null   object \n 41  CentralAir     2919 non-null   object \n 42  Electrical     2918 non-null   object \n 43  1stFlrSF       2919 non-null   int64  \n 44  2ndFlrSF       2919 non-null   int64  \n 45  LowQualFinSF   2919 non-null   int64  \n 46  GrLivArea      2919 non-null   int64  \n 47  BsmtFullBath   2917 non-null   float64\n 48  BsmtHalfBath   2917 non-null   float64\n 49  FullBath       2919 non-null   int64  \n 50  HalfBath       2919 non-null   int64  \n 51  BedroomAbvGr   2919 non-null   int64  \n 52  KitchenAbvGr   2919 non-null   int64  \n 53  KitchenQual    2918 non-null   object \n 54  TotRmsAbvGrd   2919 non-null   int64  \n 55  Functional     2917 non-null   object \n 56  Fireplaces     2919 non-null   int64  \n 57  FireplaceQu    1499 non-null   object \n 58  GarageType     2762 non-null   object \n 59  GarageYrBlt    2760 non-null   float64\n 60  GarageFinish   2760 non-null   object \n 61  GarageCars     2918 non-null   float64\n 62  GarageArea     2918 non-null   float64\n 63  GarageQual     2760 non-null   object \n 64  GarageCond     2760 non-null   object \n 65  PavedDrive     2919 non-null   object \n 66  WoodDeckSF     2919 non-null   int64  \n 67  OpenPorchSF    2919 non-null   int64  \n 68  EnclosedPorch  2919 non-null   int64  \n 69  3SsnPorch      2919 non-null   int64  \n 70  ScreenPorch    2919 non-null   int64  \n 71  PoolArea       2919 non-null   int64  \n 72  PoolQC         10 non-null     object \n 73  Fence          571 non-null    object \n 74  MiscFeature    105 non-null    object \n 75  MiscVal        2919 non-null   int64  \n 76  MoSold         2919 non-null   int64  \n 77  YrSold         2919 non-null   int64  \n 78  SaleType       2918 non-null   object \n 79  SaleCondition  2919 non-null   object \ndtypes: float64(11), int64(26), object(43)\nmemory usage: 1.8+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"# Geneate  Report and save for later use\npp.ProfileReport(X, title=\"Pandas Profiling Report\").to_file(\"report.html\")","metadata":{"execution":{"iopub.status.busy":"2024-01-31T01:03:11.822666Z","iopub.execute_input":"2024-01-31T01:03:11.823119Z","iopub.status.idle":"2024-01-31T01:09:29.922561Z","shell.execute_reply.started":"2024-01-31T01:03:11.823084Z","shell.execute_reply":"2024-01-31T01:09:29.921273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%pwd","metadata":{"execution":{"iopub.status.busy":"2024-01-31T01:10:17.884492Z","iopub.execute_input":"2024-01-31T01:10:17.884944Z","iopub.status.idle":"2024-01-31T01:10:17.893682Z","shell.execute_reply.started":"2024-01-31T01:10:17.88491Z","shell.execute_reply":"2024-01-31T01:10:17.892333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We do work on data differently based on thier type","metadata":{}},{"cell_type":"code","source":"numeric_ = X.select_dtypes(exclude=['object']).drop(['MSSubClass'], axis=1).copy()\nnumeric_.columns","metadata":{"execution":{"iopub.status.busy":"2024-01-31T11:12:50.139925Z","iopub.execute_input":"2024-01-31T11:12:50.14035Z","iopub.status.idle":"2024-01-31T11:12:50.153893Z","shell.execute_reply.started":"2024-01-31T11:12:50.140315Z","shell.execute_reply":"2024-01-31T11:12:50.152709Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Index(['Id', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',\n       'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n       'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n       'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\n       'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n       'MoSold', 'YrSold'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"#OverallQual: Overall material and finish quality (Categorical)\n#OverallCond: Overall condition rating (categorical)\n#YearBuilt: Original construction date(This column need little bit preprocessing its fine with datatype but i need to convert the dates into an int by subtracting the current date for constructed date)\n#YearRemodAdd: Remodel date (same process for this we can combinie these tow feature engineering)\n#BsmtQual: Height of the basement (ordinal encoding)\n#BsmtCond: General condition of the basement (same ordinal encoding)\n#","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"disc_num_var = ['OverallQual','OverallCond','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath',\n                'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'MoSold', 'YrSold']\n\ncont_num_var = []\nfor i in numeric_.columns:\n    if i not in disc_num_var:\n        cont_num_var.append(i)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T01:23:02.647183Z","iopub.execute_input":"2024-01-31T01:23:02.647629Z","iopub.status.idle":"2024-01-31T01:23:02.654694Z","shell.execute_reply.started":"2024-01-31T01:23:02.647598Z","shell.execute_reply":"2024-01-31T01:23:02.653518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.columns","metadata":{"execution":{"iopub.status.busy":"2024-01-31T01:23:03.604144Z","iopub.execute_input":"2024-01-31T01:23:03.604561Z","iopub.status.idle":"2024-01-31T01:23:03.612766Z","shell.execute_reply.started":"2024-01-31T01:23:03.604524Z","shell.execute_reply":"2024-01-31T01:23:03.611638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(cont_num_var)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T01:23:06.094597Z","iopub.execute_input":"2024-01-31T01:23:06.09501Z","iopub.status.idle":"2024-01-31T01:23:06.100864Z","shell.execute_reply.started":"2024-01-31T01:23:06.094975Z","shell.execute_reply":"2024-01-31T01:23:06.099687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_train = X.select_dtypes(include=['object']).copy()\ncat_train['MSSubClass'] = X['MSSubClass']   #MSSubClass is nominal\ncat_train.columns","metadata":{"execution":{"iopub.status.busy":"2024-01-31T01:27:24.143548Z","iopub.execute_input":"2024-01-31T01:27:24.144011Z","iopub.status.idle":"2024-01-31T01:27:24.160366Z","shell.execute_reply.started":"2024-01-31T01:27:24.143975Z","shell.execute_reply":"2024-01-31T01:27:24.159341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.1 Neumerical feature\n\nIn case of neumerical feature we concern about the mean, median, mood and distribution type for this box plot is the best way to look at these perameters.","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(18,16))\nfor index,col in enumerate(cont_num_var):\n    plt.subplot(6,4,index+1)\n    sns.distplot(numeric_.loc[:,col].dropna(), kde=False)\nfig.tight_layout(pad=1.0)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T01:27:27.026666Z","iopub.execute_input":"2024-01-31T01:27:27.027081Z","iopub.status.idle":"2024-01-31T01:27:37.907051Z","shell.execute_reply.started":"2024-01-31T01:27:27.02705Z","shell.execute_reply":"2024-01-31T01:27:37.905865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All these features are highly skewed (poolArea, screenporch, MiscVal), with mostly 0s. Having alot of 0s in the distribution doesnt really add information for predicting Housing Price. Hence, we will remove them during our preprocessing step\n1. BsmtFinSF2\n2. LowQualFinSF\n3. EnclosedPorch\n4. 3SsnPorch\n5. ScreenPorch\n6. PoolArea\n7. MiscVal\n\nThe above columns have most of there enteries are zero so mark them for deletion later.","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(14,15))\nfor index,col in enumerate(cont_num_var):\n    plt.subplot(6,4,index+1)\n    sns.boxplot(y=col, data=numeric_.dropna())\nfig.tight_layout(pad=1.0)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T01:27:37.908951Z","iopub.execute_input":"2024-01-31T01:27:37.909341Z","iopub.status.idle":"2024-01-31T01:27:41.83197Z","shell.execute_reply.started":"2024-01-31T01:27:37.909307Z","shell.execute_reply":"2024-01-31T01:27:41.830677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(20,15))\nfor index,col in enumerate(disc_num_var):\n    plt.subplot(5,3,index+1)\n    sns.countplot(x=col, data=numeric_.dropna())\nfig.tight_layout(pad=1.0)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T01:27:44.396044Z","iopub.execute_input":"2024-01-31T01:27:44.39647Z","iopub.status.idle":"2024-01-31T01:27:47.287182Z","shell.execute_reply.started":"2024-01-31T01:27:44.396434Z","shell.execute_reply":"2024-01-31T01:27:47.285778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.2 Categorical Features","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(18,20))\nfor index in range(len(cat_train.columns)):\n    plt.subplot(9,5,index+1)\n    sns.countplot(x=cat_train.iloc[:,index], data=cat_train.dropna())\n    plt.xticks(rotation=90)\nfig.tight_layout(pad=1.0)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T01:27:47.289599Z","iopub.execute_input":"2024-01-31T01:27:47.290075Z","iopub.status.idle":"2024-01-31T01:27:56.534356Z","shell.execute_reply.started":"2024-01-31T01:27:47.290035Z","shell.execute_reply":"2024-01-31T01:27:56.532971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Again there are some columns which are stick to one value which again do not add any valuable information so we will remove them later!","metadata":{}},{"cell_type":"markdown","source":"## Bivariant analysis\n\nwe do bivariant analysis to find relation between the variables in term of correlation matrix, multicolinearity etc.","metadata":{}},{"cell_type":"markdown","source":"This was a univariant insight of the data now we will try to find the realtionship of the differnt variables in dataframe, for this we need bivariant analysis.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14,12))\ncorrelation = numeric_.corr() \nsns.heatmap(correlation, mask = correlation <0.8, linewidth=0.5, cmap='Blues')","metadata":{"execution":{"iopub.status.busy":"2024-01-31T01:27:56.536486Z","iopub.execute_input":"2024-01-31T01:27:56.536986Z","iopub.status.idle":"2024-01-31T01:27:57.671898Z","shell.execute_reply.started":"2024-01-31T01:27:56.536952Z","shell.execute_reply":"2024-01-31T01:27:57.670701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As, it can be seen from the graph that there are some values which are highly correlated so we need to remove one of them to reduce the model coplexity.\n\nThe colums are highly correlated with self as shown. correlation of 1","metadata":{}},{"cell_type":"markdown","source":"**Relation with target variable**\n\nLets see if there is any variable that are linearly corelated with target feature those features will be most important feature in prediction so lets if there is any","metadata":{}},{"cell_type":"code","source":"numeric_train = train.select_dtypes(exclude=['object'])\ncorrelation = numeric_train.corr()\ncorrelation[['SalePrice']].sort_values(['SalePrice'], ascending=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T01:27:57.673678Z","iopub.execute_input":"2024-01-31T01:27:57.674416Z","iopub.status.idle":"2024-01-31T01:27:57.701501Z","shell.execute_reply.started":"2024-01-31T01:27:57.674373Z","shell.execute_reply":"2024-01-31T01:27:57.700293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The list above shows the linear relationship between the target variable and indipendednt variables and the top variable that are highly linearly related are very important for prediction of target variable.","metadata":{}},{"cell_type":"markdown","source":"Another way of looking at the numeric variable is to visualize the scaterplot of the columns it will help you understand if there is any other realtionship between the dependent and indipendent variables e.g Linear, Exponenetial, Quadratic etc","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(20,20))\nfor index in range(len(numeric_train.columns)):\n    plt.subplot(10,5,index+1)\n    sns.scatterplot(x=numeric_train.iloc[:,index], y='SalePrice', data=numeric_train.dropna())\nfig.tight_layout(pad=1.0)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T01:27:57.704554Z","iopub.execute_input":"2024-01-31T01:27:57.705058Z","iopub.status.idle":"2024-01-31T01:28:06.591377Z","shell.execute_reply.started":"2024-01-31T01:27:57.70501Z","shell.execute_reply":"2024-01-31T01:28:06.590078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2024-01-31T01:28:06.593424Z","iopub.execute_input":"2024-01-31T01:28:06.593875Z","iopub.status.idle":"2024-01-31T01:28:06.631641Z","shell.execute_reply.started":"2024-01-31T01:28:06.593829Z","shell.execute_reply":"2024-01-31T01:28:06.630323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Data processing\n\nSo far we have completed the part of data understanding now diving into processing the data.\n\nThis section include the follwing outliines\n\n1.  removing redundant values\n2.  dealing with outliers\n3.  Filling in missing values","metadata":{}},{"cell_type":"markdown","source":"### 2.1 removinng redundent features","metadata":{}},{"cell_type":"markdown","source":"From correlation matrix there are some features which are highly coorelated\n\n1. GarageCars GarageArea       \n2. GarageArea   GarageCars","metadata":{}},{"cell_type":"code","source":"#X.drop(['GarageCars'], axis=1, inplace=True) #Because the area has normal distribution\n#The freatures are correlated but they are very important so we desicded to keep them both","metadata":{"execution":{"iopub.status.busy":"2024-01-31T03:37:52.041302Z","iopub.execute_input":"2024-01-31T03:37:52.042183Z","iopub.status.idle":"2024-01-31T03:37:52.071671Z","shell.execute_reply.started":"2024-01-31T03:37:52.042136Z","shell.execute_reply":"2024-01-31T03:37:52.070538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### removing colums with alot missing values","metadata":{}},{"cell_type":"markdown","source":"Apart from correlation there are some colum which are almost empty and not giving any importantance.\n\nLike the below diagram shows the number of empty enteries in data from left to right where\nPoolQC,alley and MiscFeature are having greater zeros in it.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(25,8))\nplt.title('Number of missing rows')\nmissing_count = pd.DataFrame(X.isnull().sum(), columns=['sum']).sort_values(by=['sum'],ascending=False).head(20).reset_index()\nmissing_count.columns = ['features','sum']\nsns.barplot(x='features',y='sum', data = missing_count)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T01:41:31.862351Z","iopub.execute_input":"2024-01-31T01:41:31.862771Z","iopub.status.idle":"2024-01-31T01:41:32.489482Z","shell.execute_reply.started":"2024-01-31T01:41:31.862737Z","shell.execute_reply":"2024-01-31T01:41:32.488272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(X.isnull(), cbar = False)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T01:41:56.893605Z","iopub.execute_input":"2024-01-31T01:41:56.894861Z","iopub.status.idle":"2024-01-31T01:41:57.915428Z","shell.execute_reply.started":"2024-01-31T01:41:56.894787Z","shell.execute_reply":"2024-01-31T01:41:57.914257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.drop(['PoolQC','MiscFeature','Alley','Fence'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T01:44:21.985706Z","iopub.execute_input":"2024-01-31T01:44:21.986872Z","iopub.status.idle":"2024-01-31T01:44:21.997224Z","shell.execute_reply.started":"2024-01-31T01:44:21.986832Z","shell.execute_reply":"2024-01-31T01:44:21.996067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### useless features","metadata":{}},{"cell_type":"markdown","source":"remove those feature which do not have any linear relationhsip with target column","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n# Plot 1\nsns.regplot(x=numeric_train['MoSold'], y='SalePrice', data=numeric_train, ax=axes[0], line_kws={'color': 'black'})\naxes[0].set_title('MoSold vs SalePrice')\n\n# Plot 2\nsns.regplot(x=numeric_train['YrSold'], y='SalePrice', data=numeric_train, ax=axes[1], line_kws={'color': 'black'})\naxes[1].set_title('YrSold vs SalePrice')\n\n# Plot 3\nsns.regplot(x=numeric_train['PoolArea'], y='SalePrice', data=numeric_train, ax=axes[2], line_kws={'color': 'black'})\naxes[2].set_title('PoolArea vs SalePrice')\n\n# Plot 4\nsns.regplot(x=numeric_train['3SsnPorch'], y='SalePrice', data=numeric_train, ax=axes[3], line_kws={'color': 'black'})\naxes[3].set_title('3SsnPorch vs SalePrice')\n\nfig.tight_layout(pad=3.0)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:33.748359Z","iopub.execute_input":"2024-01-25T06:11:33.748682Z","iopub.status.idle":"2024-01-25T06:11:35.187122Z","shell.execute_reply.started":"2024-01-25T06:11:33.748658Z","shell.execute_reply":"2024-01-25T06:11:35.18583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correlation[['SalePrice']].sort_values(['SalePrice'], ascending=False).tail(10)\n\nX.drop(['MoSold','3SsnPorch','YrSold'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:35.188821Z","iopub.execute_input":"2024-01-25T06:11:35.189167Z","iopub.status.idle":"2024-01-25T06:11:35.201534Z","shell.execute_reply.started":"2024-01-25T06:11:35.189117Z","shell.execute_reply":"2024-01-25T06:11:35.200202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correlation","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:35.203407Z","iopub.execute_input":"2024-01-25T06:11:35.204838Z","iopub.status.idle":"2024-01-25T06:11:35.24619Z","shell.execute_reply.started":"2024-01-25T06:11:35.20477Z","shell.execute_reply":"2024-01-25T06:11:35.245331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### removing values with much single or one value\nSince these kind of feature are not giving any information and also it can fool the model and overfit to training.","metadata":{}},{"cell_type":"code","source":"cat_col = X.select_dtypes(include=['object']).columns\noverfit_cat = []\nfor i in cat_col:\n    counts = X[i].value_counts()\n    zeros = counts.iloc[0]\n    if zeros / len(X) * 100 > 96:\n        overfit_cat.append(i)\n\noverfit_cat = list(overfit_cat)\nX = X.drop(overfit_cat, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:35.247202Z","iopub.execute_input":"2024-01-25T06:11:35.248337Z","iopub.status.idle":"2024-01-25T06:11:35.285565Z","shell.execute_reply.started":"2024-01-25T06:11:35.248304Z","shell.execute_reply":"2024-01-25T06:11:35.28453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_col = X.select_dtypes(exclude=['object']).drop(['MSSubClass'], axis=1).columns\noverfit_num = []\nfor i in num_col:\n    counts = X[i].value_counts()\n    zeros = counts.iloc[0]\n    if zeros / len(X) * 100 > 96:\n        overfit_num.append(i)\n\noverfit_num = list(overfit_num)\nX = X.drop(overfit_num, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:35.286852Z","iopub.execute_input":"2024-01-25T06:11:35.287125Z","iopub.status.idle":"2024-01-25T06:11:35.31057Z","shell.execute_reply.started":"2024-01-25T06:11:35.287101Z","shell.execute_reply":"2024-01-25T06:11:35.30982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Categorical Features with >96% of the same value: \",overfit_cat)\nprint(\"Numerical Features with >96% of the same value: \",overfit_num)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:35.311801Z","iopub.execute_input":"2024-01-25T06:11:35.312626Z","iopub.status.idle":"2024-01-25T06:11:35.3183Z","shell.execute_reply.started":"2024-01-25T06:11:35.312587Z","shell.execute_reply":"2024-01-25T06:11:35.31737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape, y.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:35.319653Z","iopub.execute_input":"2024-01-25T06:11:35.320151Z","iopub.status.idle":"2024-01-25T06:11:35.339494Z","shell.execute_reply.started":"2024-01-25T06:11:35.32012Z","shell.execute_reply":"2024-01-25T06:11:35.338296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.2 Dealing with outliers\nRemoving outliers will prevent our models performance from being affected by extreme values.\nFrom our boxplot earlier, we have pinpointed the following features with extreme outliers:\n\n* LotFrontage\n* LotArea\n* BsmtFinSF2\n* BsmtFinSF\n* GrLivArea\n* MasVnrArea\n* LowQualFinSF\n* GarageArea\n* 3SsnPorch\n* ScreenPorch\n* MiscVal\n\n\nWe will remove the outliers based on certain threshold value.","metadata":{}},{"cell_type":"code","source":"out_col = ['LotFrontage', 'LotArea', 'BsmtFinSF2', 'BsmtUnfSF', 'GrLivArea', 'MasVnrArea', 'TotalBsmtSF','ScreenPorch']\nfig = plt.figure(figsize=(20,15))\nfor index,col in enumerate(out_col):\n    plt.subplot(3,5,index+1)\n    sns.boxplot(y=col, data=X)\nfig.tight_layout(pad=1.5)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:35.341117Z","iopub.execute_input":"2024-01-25T06:11:35.341448Z","iopub.status.idle":"2024-01-25T06:11:36.416064Z","shell.execute_reply.started":"2024-01-25T06:11:35.341417Z","shell.execute_reply":"2024-01-25T06:11:36.414573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_percentage_of_outliers(df, column_name):\n    column = df[column_name]\n    \n    Q1 = column.quantile(0.25)\n    Q3 = column.quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    \n    #count the percentage of outliers\n    outliers_count = ((column < lower_bound) | (column > upper_bound)).sum()\n    percentage_outliers = (outliers_count / len(column)) * 100\n    \n    #impute outliers using mean\n    outliers = (column < lower_bound) | (column > upper_bound)\n    mean_value = column.mean()\n    df[column_name] = np.where(outliers, mean_value, column)\n    return percentage_outliers\n\n\nout_col = ['LotFrontage', 'LotArea', 'BsmtFinSF2', 'BsmtUnfSF', 'GrLivArea', 'MasVnrArea', 'TotalBsmtSF','ScreenPorch']\nfor column_name in out_col:\n    percentage_outliers = find_percentage_of_outliers(X, column_name)\n    print(f\"Percentage of outliers in '{column_name}': {percentage_outliers:.2f}%\")\n","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:36.417732Z","iopub.execute_input":"2024-01-25T06:11:36.418072Z","iopub.status.idle":"2024-01-25T06:11:36.45557Z","shell.execute_reply.started":"2024-01-25T06:11:36.418035Z","shell.execute_reply":"2024-01-25T06:11:36.45276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:36.456679Z","iopub.execute_input":"2024-01-25T06:11:36.457046Z","iopub.status.idle":"2024-01-25T06:11:36.462814Z","shell.execute_reply.started":"2024-01-25T06:11:36.457012Z","shell.execute_reply":"2024-01-25T06:11:36.462032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train = train.drop(train[train['LotFrontage'] > 200].index)\n# train = train.drop(train[train['LotArea'] > 100000].index)\n# train = train.drop(train[train['BsmtFinSF2'] > 4000].index)\n# train = train.drop(train[train['BsmtUnfSF'] > 200].index)\n# train = train.drop(train[train['GrLivArea'] > 4000].index)\n# train = train.drop(train[train['MasVnrArea'] > 100000].index)\n# train = train.drop(train[train['TotalBsmtSF'] > 5000].index)\n# train = train.drop(train[train['ScreenPorch'] > 4000].index)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:36.464058Z","iopub.execute_input":"2024-01-25T06:11:36.46452Z","iopub.status.idle":"2024-01-25T06:11:36.476074Z","shell.execute_reply.started":"2024-01-25T06:11:36.464491Z","shell.execute_reply":"2024-01-25T06:11:36.474625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:36.477353Z","iopub.execute_input":"2024-01-25T06:11:36.477675Z","iopub.status.idle":"2024-01-25T06:11:36.491094Z","shell.execute_reply.started":"2024-01-25T06:11:36.477645Z","shell.execute_reply":"2024-01-25T06:11:36.489954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape,y.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:36.492797Z","iopub.execute_input":"2024-01-25T06:11:36.493427Z","iopub.status.idle":"2024-01-25T06:11:36.501652Z","shell.execute_reply.started":"2024-01-25T06:11:36.493389Z","shell.execute_reply":"2024-01-25T06:11:36.500695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.3 Filling missing values\nSince our ML models are not able to deal with the missing values in data frame so we need to remove or fill these vaues somehow so that there is no missing values exits.","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(X.isnull().sum(), columns=['sum']).sort_values(by=['sum'],ascending=False).head(15)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:36.502956Z","iopub.execute_input":"2024-01-25T06:11:36.503515Z","iopub.status.idle":"2024-01-25T06:11:36.529Z","shell.execute_reply.started":"2024-01-25T06:11:36.50348Z","shell.execute_reply":"2024-01-25T06:11:36.527864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Ordinal encoding\n\nWe will replace the ordinal missing values with NA, which will be mapped later on when we encode them into an ordered arrangement","metadata":{}},{"cell_type":"code","source":"cat = ['GarageType','GarageFinish','BsmtFinType2','BsmtExposure','BsmtFinType1', \n       'GarageCond','GarageQual','BsmtCond','BsmtQual','FireplaceQu',\"KitchenQual\",\n       \"HeatingQC\",'ExterQual','ExterCond']\n\nX[cat] = X[cat].fillna(\"NA\")","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:36.530498Z","iopub.execute_input":"2024-01-25T06:11:36.530808Z","iopub.status.idle":"2024-01-25T06:11:36.544533Z","shell.execute_reply.started":"2024-01-25T06:11:36.530781Z","shell.execute_reply":"2024-01-25T06:11:36.543564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Categorical features\nWe will replace the missing value of our categorical features with the most frequent occurrence (mode) of the individual features.","metadata":{}},{"cell_type":"code","source":"# value_counts() counts the amount of houses that show each of the labels in the variable indicated below\nX['MasVnrType'].value_counts().sort_values(ascending=False).plot.bar()\nplt.xlabel('MasVnrType')\nplt.ylabel('Number of houses')","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:36.552673Z","iopub.execute_input":"2024-01-25T06:11:36.553306Z","iopub.status.idle":"2024-01-25T06:11:36.72131Z","shell.execute_reply.started":"2024-01-25T06:11:36.553271Z","shell.execute_reply":"2024-01-25T06:11:36.720369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#categorical\ncols = [\"MasVnrType\", \"MSZoning\", \"Exterior1st\", \"Exterior2nd\", \"SaleType\", \"Electrical\", \"Functional\"]\nX[cols] = X.groupby(\"Neighborhood\")[cols].transform(lambda x: x.fillna(x.mode().iloc[0]))\n","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:36.722563Z","iopub.execute_input":"2024-01-25T06:11:36.72285Z","iopub.status.idle":"2024-01-25T06:11:36.848685Z","shell.execute_reply.started":"2024-01-25T06:11:36.722826Z","shell.execute_reply":"2024-01-25T06:11:36.847533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Numerical features\nFor Numerical Features, the common approach will be to replace the missing value with the mean of the feature distribution.\nHowever, certain features like LotFrontage have wide variance in their distribution. Taking mean values across Neighborhoods, we will see that the mean varies alot from just taking the mean value of these individual column, since each neightborhood have different LotFrontage mean value. Hence, i decided to group these features by Neighborhoods to impute the respective mean values.\n\nNote: My initial approach was based on the means of both train and test set. This exposed us to the issue of data leakage, where information from the test set is used to compute mean values. The right way to do it will be to impute solely based on the mean of the train data.\n\n","metadata":{}},{"cell_type":"code","source":"print(\"Mean of LotFrontage: \", X['LotFrontage'].mean())","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:36.8502Z","iopub.execute_input":"2024-01-25T06:11:36.850508Z","iopub.status.idle":"2024-01-25T06:11:36.856768Z","shell.execute_reply.started":"2024-01-25T06:11:36.85048Z","shell.execute_reply":"2024-01-25T06:11:36.855833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"neigh_lot = X.groupby('Neighborhood')['LotFrontage'].mean().reset_index(name='LotFrontage_mean')\n\nfig, axes = plt.subplots(figsize=(22,8))\naxes.tick_params(axis='x', rotation=90)\nsns.barplot(x='Neighborhood', y='LotFrontage_mean', data=neigh_lot, ax=axes)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:36.858087Z","iopub.execute_input":"2024-01-25T06:11:36.85845Z","iopub.status.idle":"2024-01-25T06:11:37.303321Z","shell.execute_reply.started":"2024-01-25T06:11:36.858417Z","shell.execute_reply":"2024-01-25T06:11:37.301722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for correlated relationship\nX['LotFrontage'] = X.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.mean()))\n\nX['MSZoning'] = X.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))\n\n#numerical\ncont = [\"BsmtHalfBath\", \"BsmtFullBath\", \"BsmtFinSF1\", \"BsmtFinSF2\", \"BsmtUnfSF\", \"TotalBsmtSF\", \"MasVnrArea\"]\nX[cont] = X[cont] = X[cont].fillna(X[cont].mean())","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:37.305615Z","iopub.execute_input":"2024-01-25T06:11:37.306717Z","iopub.status.idle":"2024-01-25T06:11:37.338085Z","shell.execute_reply.started":"2024-01-25T06:11:37.306666Z","shell.execute_reply":"2024-01-25T06:11:37.336875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Changing Data Type\nSince MSSubClass is an integer column based on some mapped values in string notation, we change its data type to string value instead","metadata":{}},{"cell_type":"code","source":"X['MSSubClass'] = X['MSSubClass'].apply(str)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:37.339392Z","iopub.execute_input":"2024-01-25T06:11:37.340379Z","iopub.status.idle":"2024-01-25T06:11:37.347322Z","shell.execute_reply.started":"2024-01-25T06:11:37.340345Z","shell.execute_reply":"2024-01-25T06:11:37.346083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Mapping Ordinal Features**\n\nThere are some columns which are ordinal by nature, which represents the quality or condition of certain housing features. In this case, we will map the respective strings to a value. The better the quality, the higher the value","metadata":{}},{"cell_type":"code","source":"ordinal_map = {'Ex': 5,'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA':0}\nfintype_map = {'GLQ': 6,'ALQ': 5,'BLQ': 4,'Rec': 3,'LwQ': 2,'Unf': 1, 'NA': 0}\nexpose_map = {'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1, 'NA': 0}","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:37.349015Z","iopub.execute_input":"2024-01-25T06:11:37.349463Z","iopub.status.idle":"2024-01-25T06:11:37.361018Z","shell.execute_reply.started":"2024-01-25T06:11:37.34942Z","shell.execute_reply":"2024-01-25T06:11:37.359411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ord_col = ['ExterQual','ExterCond','BsmtQual', 'BsmtCond','HeatingQC','KitchenQual','GarageQual','GarageCond', 'FireplaceQu']\nfor col in ord_col:\n    X[col] = X[col].map(ordinal_map)\n    \nfin_col = ['BsmtFinType1','BsmtFinType2']\nfor col in fin_col:\n    X[col] = X[col].map(fintype_map)\n\nX['BsmtExposure'] = X['BsmtExposure'].map(expose_map)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:37.363009Z","iopub.execute_input":"2024-01-25T06:11:37.363326Z","iopub.status.idle":"2024-01-25T06:11:37.381807Z","shell.execute_reply.started":"2024-01-25T06:11:37.363299Z","shell.execute_reply":"2024-01-25T06:11:37.38067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After removing the outliers, highly correlated features and imputing missing values, we can now proceed with adding additional information for our model to train on. This is done by the means of - Feature Engineering.","metadata":{}},{"cell_type":"code","source":"X.shape,y.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:37.384091Z","iopub.execute_input":"2024-01-25T06:11:37.384979Z","iopub.status.idle":"2024-01-25T06:11:37.400801Z","shell.execute_reply.started":"2024-01-25T06:11:37.384931Z","shell.execute_reply":"2024-01-25T06:11:37.398756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# feature engineering\nFeature Engineering is a technique by which we create new features, modify exiting features, drop features, concate features that could potentially aid in predicting our target variable, which in this case, is SalePrice. In this notebook, we will create additional features based on our Domain Knowledge of the housing features\n\nBased on the current feature we have, the first additional featuire we can add would be TotalLot, which sums up both the LotFrontage and LotArea to identify the total area of land available as lot. We can also calculate the total number of surface area of the house, TotalSF by adding the area from basement and 2nd floor. TotalBath can also be used to tell us in total how many bathrooms are there in the house. We can also add all the different types of porches around the house and generalise into a total porch area, TotalPorch.\n\n* TotalLot = LotFrontage + LotArea\n* TotalSF = TotalBsmtSF + 2ndFlrSF\n* TotalBath = FullBath + HalfBath\n* TotalPorch = OpenPorchSF + EnclosedPorch + ScreenPorch\n* TotalBsmtFin = BsmtFinSF1 + BsmtFinSF2","metadata":{}},{"cell_type":"code","source":"X['TotalLot'] = X['LotFrontage'] + X['LotArea']\nX['TotalBsmtFin'] = X['BsmtFinSF1'] + X['BsmtFinSF2']\nX['TotalSF'] = X['TotalBsmtSF'] + X['2ndFlrSF']\nX['TotalBath'] = X['FullBath'] + X['HalfBath']\nX['TotalPorch'] = X['OpenPorchSF'] + X['EnclosedPorch'] + X['ScreenPorch']","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:37.402556Z","iopub.execute_input":"2024-01-25T06:11:37.402959Z","iopub.status.idle":"2024-01-25T06:11:37.415849Z","shell.execute_reply.started":"2024-01-25T06:11:37.402927Z","shell.execute_reply":"2024-01-25T06:11:37.414347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Binay Columns\nWe also include simple feature engineering by creating binary columns for some features that can indicate the **presence(1) / absence(0**) of some features of the house","metadata":{}},{"cell_type":"code","source":"colum = ['MasVnrArea','TotalBsmtFin','TotalBsmtSF','2ndFlrSF','WoodDeckSF','TotalPorch']\n\nfor col in colum:\n    col_name = col+'_bin'\n    X[col_name] = X[col].apply(lambda x: 1 if x > 0 else 0)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:37.417831Z","iopub.execute_input":"2024-01-25T06:11:37.418121Z","iopub.status.idle":"2024-01-25T06:11:37.439873Z","shell.execute_reply.started":"2024-01-25T06:11:37.418094Z","shell.execute_reply":"2024-01-25T06:11:37.438509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Converting Categorical to Numerical\nLastly, because machine learning only learns from data that is numerical in nature, we will convert the remaining categorical columns into one-hot features using the get_dummies() method into numerical columns that is suitable for feeding into our machine learning algorithm.","metadata":{}},{"cell_type":"code","source":"X = pd.get_dummies(X)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:37.441352Z","iopub.execute_input":"2024-01-25T06:11:37.441674Z","iopub.status.idle":"2024-01-25T06:11:37.476408Z","shell.execute_reply.started":"2024-01-25T06:11:37.441647Z","shell.execute_reply":"2024-01-25T06:11:37.475251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Sales price distribution**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.title(\"Before transformation of SalePrice\")\ndist = sns.distplot(train['SalePrice'],norm_hist=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:37.478295Z","iopub.execute_input":"2024-01-25T06:11:37.478911Z","iopub.status.idle":"2024-01-25T06:11:37.819676Z","shell.execute_reply.started":"2024-01-25T06:11:37.478878Z","shell.execute_reply":"2024-01-25T06:11:37.818731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since the data is skewed towrd the right which is also called positive skewness where the long tails is at right right which also a representation of having mean is greater than its mode. So it will effect the performance of our machine learning model so we need to fix it by removing the skewness in the data by applying **log transformation**.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.title(\"After transformation of SalePrice\")\ndist = sns.distplot(np.log(train['SalePrice']),norm_hist=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:37.820739Z","iopub.execute_input":"2024-01-25T06:11:37.821Z","iopub.status.idle":"2024-01-25T06:11:38.509099Z","shell.execute_reply.started":"2024-01-25T06:11:37.820978Z","shell.execute_reply":"2024-01-25T06:11:38.508409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y[\"SalePrice\"] = np.log(y['SalePrice'])","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:38.510339Z","iopub.execute_input":"2024-01-25T06:11:38.510818Z","iopub.status.idle":"2024-01-25T06:11:38.517432Z","shell.execute_reply.started":"2024-01-25T06:11:38.510785Z","shell.execute_reply":"2024-01-25T06:11:38.515223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Modeling\nThis section will consist of scaling the data for better optimization in our training, and also introducing the varieties of ensembling methods that are used in this notebook for predicting the Housing price. We also try out hyperparameter tuning briefly, as i will be dedicating a new notebook that will explain more in details on the process of Hyperparameter Tuning as well as the mathematical aspect of the ensemble algorithms.","metadata":{}},{"cell_type":"markdown","source":"#### train test and validation split","metadata":{}},{"cell_type":"code","source":"X.shape,y.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:38.519043Z","iopub.execute_input":"2024-01-25T06:11:38.51945Z","iopub.status.idle":"2024-01-25T06:11:38.529981Z","shell.execute_reply.started":"2024-01-25T06:11:38.519411Z","shell.execute_reply":"2024-01-25T06:11:38.529005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#x2 = X.loc[train.index]\n#y2 = y.loc[train.index]\n#test2 = X.loc[test.index]","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:38.531856Z","iopub.execute_input":"2024-01-25T06:11:38.5323Z","iopub.status.idle":"2024-01-25T06:11:38.542902Z","shell.execute_reply.started":"2024-01-25T06:11:38.532265Z","shell.execute_reply":"2024-01-25T06:11:38.541519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming X contains both train and test data\ntrain_rows = len(train)\ntrain_X = X.iloc[:train_rows, :]\ntest_X = X.iloc[train_rows:, :]\n","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:38.544611Z","iopub.execute_input":"2024-01-25T06:11:38.545083Z","iopub.status.idle":"2024-01-25T06:11:38.555954Z","shell.execute_reply.started":"2024-01-25T06:11:38.545041Z","shell.execute_reply":"2024-01-25T06:11:38.554995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_X.shape,test_X.shape,y.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:38.557285Z","iopub.execute_input":"2024-01-25T06:11:38.557753Z","iopub.status.idle":"2024-01-25T06:11:38.570211Z","shell.execute_reply.started":"2024-01-25T06:11:38.557721Z","shell.execute_reply":"2024-01-25T06:11:38.569125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Scaling of data\n**RobustScaler** is a transformation technique that removes the median and scales the data according to the quantile range (defaults to IQR: Interquartile Range). The IQR is the range between the 1st quartile (25th quantile) and the 3rd quartile (75th quantile). It is also robust to outliers, which makes it ideal for data where there are too many outliers that will drastically reduce the number of training data.\n\nPreviously i fitted the RobustScaler on both Train and Test set, and that is a mistake on my side. By fitting the scaler on both train and testset, we exposed ourselves to the problem of **Data Leakage**. Data Leakage is a problem when information from outside the training dataset is used to create the model. If we fit the scaler on both training and test data, our training data characteristics will contain the distribution of our testset. As such, we are unknowningly passing in information about our test data into the final training data for training, which will not give us the opportunity to truly test our model on data it has never seen before\n\n**Lesson Learnt:** Fit the scaler just on training data, and then transforming it on both training and test data","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Enasamble algorithm\n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(train_X, y, test_size=0.2, random_state=2020)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:38.571337Z","iopub.execute_input":"2024-01-25T06:11:38.571676Z","iopub.status.idle":"2024-01-25T06:11:38.585004Z","shell.execute_reply.started":"2024-01-25T06:11:38.571634Z","shell.execute_reply":"2024-01-25T06:11:38.584038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler\n\ncols = X_train.select_dtypes(np.number).columns\ntransformer = RobustScaler().fit(X_train[cols])\ntrain_X[cols] = transformer.transform(train_X[cols])\ntest_X[cols] = transformer.transform(test_X[cols])","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:38.586312Z","iopub.execute_input":"2024-01-25T06:11:38.586839Z","iopub.status.idle":"2024-01-25T06:11:38.629532Z","shell.execute_reply.started":"2024-01-25T06:11:38.586804Z","shell.execute_reply":"2024-01-25T06:11:38.628555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Ensamble models.\nEnsembling methods are meta-algorithms which involves combining several machine learning models into one predictive model, aim at decreasing variance(reduce overfitting) and improving bias(improve accuracy).\nThe 3 main ensembling methods are **Bagging, Boosting and Stacking**.\nIn this notebook, we will focus mainly on Boosting, which is what we will be using for our prediction.\n\n**Boosting** works on a class of weak learners, improving them into strong learners. It is being improved sequentially where the misclassified instances will be given more weights so that during the subsequent training, the learner will place more emphasis in correcting the previously misclassfied instance, less so on the already correctly identified instances. Over time, the eventual learner will possess the ability to predict accurately as a result of learning from past mistakes","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom xgboost import XGBRegressor\nfrom sklearn import ensemble\nfrom lightgbm import LGBMRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom catboost import CatBoostRegressor","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:08.25067Z","iopub.execute_input":"2024-01-25T06:11:08.251083Z","iopub.status.idle":"2024-01-25T06:11:08.257352Z","shell.execute_reply.started":"2024-01-25T06:11:08.251046Z","shell.execute_reply":"2024-01-25T06:11:08.255955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**XGBoost**\n\nExtreme Gradient Boost (XGB) is a boosting algorithm that uses the gradient boosting framework; where gradient descent algorithm is employed to minimize the errors in the sequential model. It improves on the gradient boosting framework with faster execution speed and improved performance.","metadata":{}},{"cell_type":"code","source":"'''\nFind out more on the XGBRegressor implementation and parameters at \nhttps://xgboost.readthedocs.io/en/latest/parameter.html#parameters-for-tree-booster\n'''\n\n# xgb = XGBRegressor(booster='gbtree', learning_rate=0.3, n_estimators=3460,\n#                     max_depth=6, min_child_weight=1, subsample=1,\n#                     gamma=0, reg_alpha = 0.001, colsample_bytree=0.7,\n#                     objective='reg:squarederror', reg_lambda = 0.001,\n#                     scale_pos_weight=1, seed=2020)\n\nxgb = XGBRegressor(booster='gbtree', objective='reg:squarederror')","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:08.288114Z","iopub.execute_input":"2024-01-25T06:11:08.288448Z","iopub.status.idle":"2024-01-25T06:11:08.293216Z","shell.execute_reply.started":"2024-01-25T06:11:08.288422Z","shell.execute_reply":"2024-01-25T06:11:08.292121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\nparam_lst = {\n    'learning_rate' : [0.01, 0.1, 0.15, 0.3, 0.5],\n    'n_estimators' : [100, 500, 1000, 2000, 3000],\n    'max_depth' : [3, 6, 9],\n    'min_child_weight' : [1, 5, 10, 20],\n    'reg_alpha' : [0.001, 0.01, 0.1],\n    'reg_lambda' : [0.001, 0.01, 0.1]\n}\n\nxgb_reg = RandomizedSearchCV(estimator = xgb, param_distributions = param_lst,\n                              n_iter = 100, scoring = 'neg_root_mean_squared_error',\n                              cv = 5)\n       \nxgb_search = xgb_reg.fit(X_train, y_train)\n\n# XGB with tune hyperparameters\nbest_param = xgb_search.best_params_\nxgb = XGBRegressor(**best_param)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:11:38.630866Z","iopub.execute_input":"2024-01-25T06:11:38.631182Z","iopub.status.idle":"2024-01-25T06:27:17.692531Z","shell.execute_reply.started":"2024-01-25T06:11:38.631156Z","shell.execute_reply":"2024-01-25T06:27:17.691805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_param","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:27:17.693963Z","iopub.execute_input":"2024-01-25T06:27:17.694398Z","iopub.status.idle":"2024-01-25T06:27:17.698493Z","shell.execute_reply.started":"2024-01-25T06:27:17.694373Z","shell.execute_reply":"2024-01-25T06:27:17.697947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Training and Evaluation","metadata":{}},{"cell_type":"code","source":"def mean_cross_val(model, X, y):\n    score = cross_val_score(model, X, y, cv=5)\n    mean = score.mean()\n    return mean\n\nxgb.fit(X_train, y_train)   \npreds = xgb.predict(X_val) \n","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:27:17.699683Z","iopub.execute_input":"2024-01-25T06:27:17.700243Z","iopub.status.idle":"2024-01-25T06:27:18.610945Z","shell.execute_reply.started":"2024-01-25T06:27:17.700219Z","shell.execute_reply":"2024-01-25T06:27:18.610229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_test_xgb = xgb.predict(test_X)\nmae_xgb = mean_absolute_error(y_val, preds)\nrmse_xgb = np.sqrt(mean_squared_error(y_val, preds))\nscore_xgb = xgb.score(X_val, y_val)\ncv_xgb = mean_cross_val(xgb, train_X, y)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:27:18.612264Z","iopub.execute_input":"2024-01-25T06:27:18.612736Z","iopub.status.idle":"2024-01-25T06:27:23.277375Z","shell.execute_reply.started":"2024-01-25T06:27:18.61271Z","shell.execute_reply":"2024-01-25T06:27:23.276394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_performances = pd.DataFrame({\n    \"Model\" : [\"XGBoost\"],\n    \"CV(5)\" : [str(cv_xgb)[0:5]],\n    \"MAE\" : [str(mae_xgb)[0:5]],\n    \"RMSE\" : [str(rmse_xgb)[0:5]],\n    \"Score\" : [str(score_xgb)[0:5]] })\n\nprint(\"Sorted by Score:\")\nprint(model_performances.sort_values(by=\"Score\", ascending=False))","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:27:23.2786Z","iopub.execute_input":"2024-01-25T06:27:23.279374Z","iopub.status.idle":"2024-01-25T06:27:23.288702Z","shell.execute_reply.started":"2024-01-25T06:27:23.279344Z","shell.execute_reply":"2024-01-25T06:27:23.287378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subm = np.exp(xgb.predict(test_X))\n\n# Assuming 1060 is the starting value for the \"Id\" column\nstart_id = 1461\n\n# Create the submission DataFrame\nsubmission = pd.DataFrame({'Id': range(start_id, start_id + len(test_X)),\n                            'SalePrice': subm})\n\nsubmission.to_csv(\"../../kaggle/working/submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T06:27:23.289945Z","iopub.execute_input":"2024-01-25T06:27:23.290236Z","iopub.status.idle":"2024-01-25T06:27:23.350913Z","shell.execute_reply.started":"2024-01-25T06:27:23.290209Z","shell.execute_reply":"2024-01-25T06:27:23.350066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Resources that i uses\n\nhttps://www.kaggle.com/code/angqx95/data-science-workflow-top-2-with-tuning\nhttps://www.analyticsvidhya.com/blog/2016/01/guide-data-exploration/\nhttps://medium.com/cracking-the-data-science-interview/the-10-statistical-techniques-data-scientists-need-to-master-1ef6dbd531f7 https://www.analyticsvidhya.com/blog/2017/06/which-algorithm-takes-the-crown-light-gbm-vs-xgboost/\n\n\n\n\nhttps://www.kaggle.com/code/masumrumi/a-detailed-regression-guide-with-house-pricing\n#https://www.kaggle.com/code/bsivavenu/house-price-calculation-methods-for-beginners\nhttps://www.kaggle.com/code/jesucristo/1-house-prices-solution-top-1\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}